{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "LR = 1e-2\n",
    "BS = 16384\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## 시드고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = pd.read_csv('./val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## 1D AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(30,90),\n",
    "            nn.BatchNorm1d(90),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(90,150),\n",
    "            nn.BatchNorm1d(150),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(150,90),\n",
    "            nn.BatchNorm1d(90),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(90,30),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train (학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self, ):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train loss : [0.5368079159940992] Val Score : [0.0028453569581759065])\n",
      "Epoch : [1] Train loss : [0.3531084784439632] Val Score : [0.11501328578873722])\n",
      "Epoch : [2] Train loss : [0.2670650950499943] Val Score : [0.30215156887714245])\n",
      "Epoch : [3] Train loss : [0.2175464928150177] Val Score : [0.3790190027871001])\n",
      "Epoch : [4] Train loss : [0.18641855461256845] Val Score : [0.44666852712828586])\n",
      "Epoch : [5] Train loss : [0.16549089550971985] Val Score : [0.4737767031394002])\n",
      "Epoch : [6] Train loss : [0.15075396852833883] Val Score : [0.48597195851029973])\n",
      "Epoch : [7] Train loss : [0.14078528540475027] Val Score : [0.49245822793194194])\n",
      "Epoch : [8] Train loss : [0.1326482892036438] Val Score : [0.49735580431507725])\n",
      "Epoch : [9] Train loss : [0.1282434623156275] Val Score : [0.5004386933604956])\n",
      "Epoch : [10] Train loss : [0.12294097138302666] Val Score : [0.5021549338455491])\n",
      "Epoch : [11] Train loss : [0.11813775237117495] Val Score : [0.5036468616836273])\n",
      "Epoch : [12] Train loss : [0.1145084063921656] Val Score : [0.5051778013969025])\n",
      "Epoch : [13] Train loss : [0.11019038834742137] Val Score : [0.5071917899657834])\n",
      "Epoch : [14] Train loss : [0.10679371016366142] Val Score : [0.5084788454280785])\n",
      "Epoch : [15] Train loss : [0.10367789651666369] Val Score : [0.5103823803482188])\n",
      "Epoch : [16] Train loss : [0.10140838154724666] Val Score : [0.5115713584390614])\n",
      "Epoch : [17] Train loss : [0.09958720313651222] Val Score : [0.5128508316275361])\n",
      "Epoch : [18] Train loss : [0.09662286298615592] Val Score : [0.5148926238475761])\n",
      "Epoch : [19] Train loss : [0.09316446738583702] Val Score : [0.5159338133164293])\n",
      "Epoch : [20] Train loss : [0.0918038689664432] Val Score : [0.5171281923429423])\n",
      "Epoch : [21] Train loss : [0.08927527708666665] Val Score : [0.5190998094691492])\n",
      "Epoch : [22] Train loss : [0.08742720953055791] Val Score : [0.5193295312276188])\n",
      "Epoch : [23] Train loss : [0.08686814776488713] Val Score : [0.5195227096067735])\n",
      "Epoch : [24] Train loss : [0.08579030739409584] Val Score : [0.5213372477849859])\n",
      "Epoch : [25] Train loss : [0.08490109017917088] Val Score : [0.5219317359651965])\n",
      "Epoch : [26] Train loss : [0.080667858677251] Val Score : [0.5222347283022847])\n",
      "Epoch : [27] Train loss : [0.07901627038206373] Val Score : [0.5237181594008616])\n",
      "Epoch : [28] Train loss : [0.0786694809794426] Val Score : [0.5243767796796488])\n",
      "Epoch : [29] Train loss : [0.07842282099383217] Val Score : [0.524858674155579])\n",
      "Epoch : [30] Train loss : [0.07909946569374629] Val Score : [0.526313884469248])\n",
      "Epoch : [31] Train loss : [0.07634362365518298] Val Score : [0.5270492955671493])\n",
      "Epoch : [32] Train loss : [0.07482908985444478] Val Score : [0.527807788775894])\n",
      "Epoch : [33] Train loss : [0.07515367546251842] Val Score : [0.5311011325592798])\n",
      "Epoch : [34] Train loss : [0.07464323618582316] Val Score : [0.5328593190650799])\n",
      "Epoch : [35] Train loss : [0.07135149517229625] Val Score : [0.5338913307706434])\n",
      "Epoch : [36] Train loss : [0.07253774042640414] Val Score : [0.5357840109763295])\n",
      "Epoch : [37] Train loss : [0.0717391020485333] Val Score : [0.5385672581308983])\n",
      "Epoch : [38] Train loss : [0.07217829248734883] Val Score : [0.5426217169100375])\n",
      "Epoch : [39] Train loss : [0.0730249040893146] Val Score : [0.5441140534215738])\n",
      "Epoch : [40] Train loss : [0.0714082345366478] Val Score : [0.5448377414221778])\n",
      "Epoch : [41] Train loss : [0.06859744978802544] Val Score : [0.5507171941799006])\n",
      "Epoch : [42] Train loss : [0.06732245428221566] Val Score : [0.5556525296376691])\n",
      "Epoch : [43] Train loss : [0.06697092950344086] Val Score : [0.5567046530896047])\n",
      "Epoch : [44] Train loss : [0.06744544633797236] Val Score : [0.5568576743388275])\n",
      "Epoch : [45] Train loss : [0.06757743124450956] Val Score : [0.5604091444190722])\n",
      "Epoch : [46] Train loss : [0.06610897076981408] Val Score : [0.5609226813318595])\n",
      "Epoch : [47] Train loss : [0.06508450848715645] Val Score : [0.5639801983006851])\n",
      "Epoch : [48] Train loss : [0.061913612697805674] Val Score : [0.5692054548941593])\n",
      "Epoch : [49] Train loss : [0.06463169093642916] Val Score : [0.5705190893059827])\n",
      "Epoch : [50] Train loss : [0.06289389676281384] Val Score : [0.5723410221437316])\n",
      "Epoch : [51] Train loss : [0.0620781561093671] Val Score : [0.5811257888292362])\n",
      "Epoch : [52] Train loss : [0.06362825472440038] Val Score : [0.5892638238382694])\n",
      "Epoch : [53] Train loss : [0.06283520694289889] Val Score : [0.6090673860606592])\n",
      "Epoch : [54] Train loss : [0.060797191091946194] Val Score : [0.6275968096299891])\n",
      "Epoch : [55] Train loss : [0.062341321791921346] Val Score : [0.66357535404777])\n",
      "Epoch : [56] Train loss : [0.06083008274435997] Val Score : [0.699339777108752])\n",
      "Epoch : [57] Train loss : [0.05933738233787673] Val Score : [0.699339777108752])\n",
      "Epoch : [58] Train loss : [0.06002730982644217] Val Score : [0.7026094381998027])\n",
      "Epoch : [59] Train loss : [0.05907575041055679] Val Score : [0.7009614947751022])\n",
      "Epoch : [60] Train loss : [0.06119372057063239] Val Score : [0.7026094381998027])\n",
      "Epoch : [61] Train loss : [0.061511648020574024] Val Score : [0.7059866032567539])\n",
      "Epoch : [62] Train loss : [0.059460362153393884] Val Score : [0.7042842522861986])\n",
      "Epoch : [63] Train loss : [0.05756191536784172] Val Score : [0.699339777108752])\n",
      "Epoch : [64] Train loss : [0.05768828147224018] Val Score : [0.7042842522861986])\n",
      "Epoch : [65] Train loss : [0.057267424783536365] Val Score : [0.7059866032567539])\n",
      "Epoch : [66] Train loss : [0.05689486169389316] Val Score : [0.7077171795413468])\n",
      "Epoch : [67] Train loss : [0.058176741536174505] Val Score : [0.7042842522861986])\n",
      "Epoch : [68] Train loss : [0.055376560028110235] Val Score : [0.7187349645015549])\n",
      "Epoch : [69] Train loss : [0.053469267806836536] Val Score : [0.7042842522861986])\n",
      "Epoch : [70] Train loss : [0.055288893835885186] Val Score : [0.7059866032567539])\n",
      "Epoch : [71] Train loss : [0.055084540375641415] Val Score : [0.7026094381998027])\n",
      "Epoch : [72] Train loss : [0.05697260318057878] Val Score : [0.7112658784551884])\n",
      "Epoch : [73] Train loss : [0.05598401704004833] Val Score : [0.7112658784551884])\n",
      "Epoch : [74] Train loss : [0.05440259724855423] Val Score : [0.7094766927103557])\n",
      "Epoch : [75] Train loss : [0.05341536392058645] Val Score : [0.7168192118976862])\n",
      "Epoch : [76] Train loss : [0.056634709771190374] Val Score : [0.7187349645015549])\n",
      "Epoch : [77] Train loss : [0.05295560508966446] Val Score : [0.7267446884090669])\n",
      "Epoch : [78] Train loss : [0.05294364903654371] Val Score : [0.7246883762645999])\n",
      "Epoch : [79] Train loss : [0.05294502952269146] Val Score : [0.7206844679680786])\n",
      "Epoch : [80] Train loss : [0.05402084014245442] Val Score : [0.7226686263465465])\n",
      "Epoch : [81] Train loss : [0.05536935265575137] Val Score : [0.7288385690883094])\n",
      "Epoch : [82] Train loss : [0.05403997749090195] Val Score : [0.7288385690883094])\n",
      "Epoch : [83] Train loss : [0.050975369555609565] Val Score : [0.7353562550268086])\n",
      "Epoch : [84] Train loss : [0.05040690302848816] Val Score : [0.7495600450513867])\n",
      "Epoch : [85] Train loss : [0.05063291426215853] Val Score : [0.75467969893057])\n",
      "Epoch : [86] Train loss : [0.053738094334091456] Val Score : [0.7331432493795871])\n",
      "Epoch : [87] Train loss : [0.052302275385175435] Val Score : [0.7353562550268086])\n",
      "Epoch : [88] Train loss : [0.05253292087997709] Val Score : [0.7470759905302604])\n",
      "Epoch : [89] Train loss : [0.0498781039246491] Val Score : [0.7495600450513867])\n",
      "Epoch : [90] Train loss : [0.050572066966976435] Val Score : [0.75467969893057])\n",
      "Epoch : [91] Train loss : [0.04819360428622791] Val Score : [0.7470759905302604])\n",
      "Epoch : [92] Train loss : [0.047896342618124824] Val Score : [0.75467969893057])\n",
      "Epoch : [93] Train loss : [0.049852781529937475] Val Score : [0.7600119366040216])\n",
      "Epoch : [94] Train loss : [0.04855944641998836] Val Score : [0.7600119366040216])\n",
      "Epoch : [95] Train loss : [0.04804773469056402] Val Score : [0.7713696202996474])\n",
      "Epoch : [96] Train loss : [0.04990486268486295] Val Score : [0.762761970120889])\n",
      "Epoch : [97] Train loss : [0.04767530730792454] Val Score : [0.7743645687973808])\n",
      "Epoch : [98] Train loss : [0.04919728157775743] Val Score : [0.7684388896488608])\n",
      "Epoch : [99] Train loss : [0.04736382780330522] Val Score : [0.7655703273293624])\n",
      "Epoch : [100] Train loss : [0.049940330641610284] Val Score : [0.7600119366040216])\n",
      "Epoch : [101] Train loss : [0.04789079140339579] Val Score : [0.7684388896488608])\n",
      "Epoch : [102] Train loss : [0.04731224636946406] Val Score : [0.7805557779616334])\n",
      "Epoch : [103] Train loss : [0.04566219715135438] Val Score : [0.7837566139258728])\n",
      "Epoch : [104] Train loss : [0.04840096352355821] Val Score : [0.7713696202996474])\n",
      "Epoch : [105] Train loss : [0.0477496257850102] Val Score : [0.7837566139258728])\n",
      "Epoch : [106] Train loss : [0.046926582498209815] Val Score : [0.7743645687973808])\n",
      "Epoch : [107] Train loss : [0.04748811945319176] Val Score : [0.7903809848799157])\n",
      "Epoch : [108] Train loss : [0.046636094472237995] Val Score : [0.7870308296420961])\n",
      "Epoch : [109] Train loss : [0.046818845506225316] Val Score : [0.7870308296420961])\n",
      "Epoch : [110] Train loss : [0.049100560801369805] Val Score : [0.7837566139258728])\n",
      "Epoch : [111] Train loss : [0.04662869019167764] Val Score : [0.7903809848799157])\n",
      "Epoch : [112] Train loss : [0.045773547142744064] Val Score : [0.808369294415656])\n",
      "Epoch : [113] Train loss : [0.04808713921478817] Val Score : [0.8162006166001039])\n",
      "Epoch : [114] Train loss : [0.048339296132326126] Val Score : [0.8202665410912253])\n",
      "Epoch : [115] Train loss : [0.046202831502471654] Val Score : [0.833113452596645])\n",
      "Epoch : [116] Train loss : [0.04508957426462855] Val Score : [0.8422634702634115])\n",
      "Epoch : [117] Train loss : [0.04648120382002422] Val Score : [0.856966968023358])\n",
      "Epoch : [118] Train loss : [0.04577287712267467] Val Score : [0.8674887641844412])\n",
      "Epoch : [119] Train loss : [0.04461449757218361] Val Score : [0.8786471773914175])\n",
      "Epoch : [120] Train loss : [0.04485282248684338] Val Score : [0.8786471773914175])\n",
      "Epoch : [121] Train loss : [0.044621706541095464] Val Score : [0.8844834793761085])\n",
      "Epoch : [122] Train loss : [0.045278653502464294] Val Score : [0.890501890608512])\n",
      "Epoch : [123] Train loss : [0.043910542236907144] Val Score : [0.890501890608512])\n",
      "Epoch : [124] Train loss : [0.046267165669373105] Val Score : [0.8844834793761085])\n",
      "Epoch : [125] Train loss : [0.04522047085421426] Val Score : [0.8967110829723166])\n",
      "Epoch : [126] Train loss : [0.04483451481376376] Val Score : [0.9031202878275757])\n",
      "Epoch : [127] Train loss : [0.043334552219935825] Val Score : [0.890501890608512])\n",
      "Epoch : [128] Train loss : [0.045847878392253606] Val Score : [0.9097393418694286])\n",
      "Epoch : [129] Train loss : [0.04445664158889225] Val Score : [0.890501890608512])\n",
      "Epoch : [130] Train loss : [0.04205069850598063] Val Score : [0.8844834793761085])\n",
      "Epoch : [131] Train loss : [0.04200026871902602] Val Score : [0.890501890608512])\n",
      "Epoch : [132] Train loss : [0.04280970458473478] Val Score : [0.9097393418694286])\n",
      "Epoch : [133] Train loss : [0.04259638701166425] Val Score : [0.9097393418694286])\n",
      "Epoch : [134] Train loss : [0.041166145886693685] Val Score : [0.9097393418694286])\n",
      "Epoch : [135] Train loss : [0.04363573981182916] Val Score : [0.9031202878275757])\n",
      "Epoch : [136] Train loss : [0.043293683656624386] Val Score : [0.9097393418694286])\n",
      "Epoch : [137] Train loss : [0.04292063042521477] Val Score : [0.9097393418694286])\n",
      "Epoch : [138] Train loss : [0.04041240204657827] Val Score : [0.9097393418694286])\n",
      "Epoch : [139] Train loss : [0.041990138590335846] Val Score : [0.9097393418694286])\n",
      "Epoch   140: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch : [140] Train loss : [0.03691997112972396] Val Score : [0.9097393418694286])\n",
      "Epoch : [141] Train loss : [0.035747709551027844] Val Score : [0.9097393418694286])\n",
      "Epoch : [142] Train loss : [0.03841710409947804] Val Score : [0.9097393418694286])\n",
      "Epoch : [143] Train loss : [0.038035233105931966] Val Score : [0.9097393418694286])\n",
      "Epoch : [144] Train loss : [0.0362382030912808] Val Score : [0.9097393418694286])\n",
      "Epoch : [145] Train loss : [0.03463247285357544] Val Score : [0.9097393418694286])\n",
      "Epoch : [146] Train loss : [0.03605266447578158] Val Score : [0.9097393418694286])\n",
      "Epoch : [147] Train loss : [0.03824313942875181] Val Score : [0.9097393418694286])\n",
      "Epoch : [148] Train loss : [0.036214157938957214] Val Score : [0.9097393418694286])\n",
      "Epoch : [149] Train loss : [0.03501437444772039] Val Score : [0.9097393418694286])\n",
      "Epoch : [150] Train loss : [0.03473080747893879] Val Score : [0.9097393418694286])\n",
      "Epoch   151: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch : [151] Train loss : [0.032502097210713794] Val Score : [0.9097393418694286])\n",
      "Epoch : [152] Train loss : [0.032206932082772255] Val Score : [0.9097393418694286])\n",
      "Epoch : [153] Train loss : [0.03065344105873789] Val Score : [0.9097393418694286])\n",
      "Epoch : [154] Train loss : [0.030561798119119236] Val Score : [0.9097393418694286])\n",
      "Epoch : [155] Train loss : [0.028971723413893154] Val Score : [0.9097393418694286])\n",
      "Epoch : [156] Train loss : [0.029369779729417393] Val Score : [0.9097393418694286])\n",
      "Epoch : [157] Train loss : [0.031199463243995394] Val Score : [0.9097393418694286])\n",
      "Epoch : [158] Train loss : [0.030449151726705686] Val Score : [0.9097393418694286])\n",
      "Epoch : [159] Train loss : [0.031939419518624036] Val Score : [0.9097393418694286])\n",
      "Epoch : [160] Train loss : [0.03032666364950793] Val Score : [0.9097393418694286])\n",
      "Epoch : [161] Train loss : [0.0303037092089653] Val Score : [0.9097393418694286])\n",
      "Epoch   162: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch : [162] Train loss : [0.02973719739488193] Val Score : [0.9097393418694286])\n",
      "Epoch : [163] Train loss : [0.02808917367032596] Val Score : [0.9097393418694286])\n",
      "Epoch : [164] Train loss : [0.027230909626398767] Val Score : [0.9097393418694286])\n",
      "Epoch : [165] Train loss : [0.029171517118811607] Val Score : [0.9097393418694286])\n",
      "Epoch : [166] Train loss : [0.029176019930413792] Val Score : [0.9097393418694286])\n",
      "Epoch : [167] Train loss : [0.027959594503045082] Val Score : [0.9097393418694286])\n",
      "Epoch : [168] Train loss : [0.028856614072407995] Val Score : [0.9097393418694286])\n",
      "Epoch : [169] Train loss : [0.027359146624803543] Val Score : [0.9097393418694286])\n",
      "Epoch : [170] Train loss : [0.028292992019227574] Val Score : [0.9097393418694286])\n",
      "Epoch : [171] Train loss : [0.026073188121829714] Val Score : [0.9097393418694286])\n",
      "Epoch : [172] Train loss : [0.02880572501037802] Val Score : [0.9097393418694286])\n",
      "Epoch   173: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch : [173] Train loss : [0.02786546546433653] Val Score : [0.9097393418694286])\n",
      "Epoch : [174] Train loss : [0.028200922533869743] Val Score : [0.9097393418694286])\n",
      "Epoch : [175] Train loss : [0.027931413214121546] Val Score : [0.9097393418694286])\n",
      "Epoch : [176] Train loss : [0.02853657172194549] Val Score : [0.9097393418694286])\n",
      "Epoch : [177] Train loss : [0.026597900848303522] Val Score : [0.9097393418694286])\n",
      "Epoch : [178] Train loss : [0.026672191385711943] Val Score : [0.9097393418694286])\n",
      "Epoch : [179] Train loss : [0.027976990012185916] Val Score : [0.9097393418694286])\n",
      "Epoch : [180] Train loss : [0.026331872812339237] Val Score : [0.9097393418694286])\n",
      "Epoch : [181] Train loss : [0.02842495989586626] Val Score : [0.9097393418694286])\n",
      "Epoch : [182] Train loss : [0.027538936585187912] Val Score : [0.9097393418694286])\n",
      "Epoch : [183] Train loss : [0.025996456987091472] Val Score : [0.9097393418694286])\n",
      "Epoch   184: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch : [184] Train loss : [0.02738709348653044] Val Score : [0.9097393418694286])\n",
      "Epoch : [185] Train loss : [0.02640391300831522] Val Score : [0.9097393418694286])\n",
      "Epoch : [186] Train loss : [0.02549543870346887] Val Score : [0.9097393418694286])\n",
      "Epoch : [187] Train loss : [0.027620938207421983] Val Score : [0.9097393418694286])\n",
      "Epoch : [188] Train loss : [0.025067676390920366] Val Score : [0.9097393418694286])\n",
      "Epoch : [189] Train loss : [0.02680504002741405] Val Score : [0.9097393418694286])\n",
      "Epoch : [190] Train loss : [0.027509467410189763] Val Score : [0.9097393418694286])\n",
      "Epoch : [191] Train loss : [0.027361576578446796] Val Score : [0.9097393418694286])\n",
      "Epoch : [192] Train loss : [0.02684037626854011] Val Score : [0.9097393418694286])\n",
      "Epoch : [193] Train loss : [0.025617072358727455] Val Score : [0.9097393418694286])\n",
      "Epoch : [194] Train loss : [0.025740016783986772] Val Score : [0.9097393418694286])\n",
      "Epoch   195: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch : [195] Train loss : [0.027374109785471643] Val Score : [0.9097393418694286])\n",
      "Epoch : [196] Train loss : [0.026229734399488995] Val Score : [0.9097393418694286])\n",
      "Epoch : [197] Train loss : [0.026126784405538013] Val Score : [0.9097393418694286])\n",
      "Epoch : [198] Train loss : [0.025682263874581883] Val Score : [0.9097393418694286])\n",
      "Epoch : [199] Train loss : [0.024715582973190715] Val Score : [0.9097393418694286])\n",
      "Epoch : [200] Train loss : [0.026121347344347408] Val Score : [0.9097393418694286])\n",
      "Epoch : [201] Train loss : [0.02620456580604826] Val Score : [0.9097393418694286])\n",
      "Epoch : [202] Train loss : [0.02884369476565293] Val Score : [0.9097393418694286])\n",
      "Epoch : [203] Train loss : [0.02616553141602448] Val Score : [0.9097393418694286])\n",
      "Epoch : [204] Train loss : [0.025543798027294024] Val Score : [0.9097393418694286])\n",
      "Epoch : [205] Train loss : [0.024911866390279362] Val Score : [0.9097393418694286])\n",
      "Epoch   206: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch : [206] Train loss : [0.024796710748757635] Val Score : [0.9097393418694286])\n",
      "Epoch : [207] Train loss : [0.026303710948143686] Val Score : [0.9097393418694286])\n",
      "Epoch : [208] Train loss : [0.026299394933240756] Val Score : [0.9097393418694286])\n",
      "Epoch : [209] Train loss : [0.026423010709030286] Val Score : [0.9097393418694286])\n",
      "Epoch : [210] Train loss : [0.02506739859070097] Val Score : [0.9097393418694286])\n",
      "Epoch : [211] Train loss : [0.026580549510461942] Val Score : [0.9097393418694286])\n",
      "Epoch : [212] Train loss : [0.026574219710060527] Val Score : [0.9097393418694286])\n",
      "Epoch : [213] Train loss : [0.02598524040409497] Val Score : [0.9097393418694286])\n",
      "Epoch : [214] Train loss : [0.0253422385347741] Val Score : [0.9097393418694286])\n",
      "Epoch : [215] Train loss : [0.025916068415556635] Val Score : [0.9097393418694286])\n",
      "Epoch : [216] Train loss : [0.025520114760313715] Val Score : [0.9097393418694286])\n",
      "Epoch   217: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch : [217] Train loss : [0.02595301398209163] Val Score : [0.9097393418694286])\n",
      "Epoch : [218] Train loss : [0.02593050790684564] Val Score : [0.9097393418694286])\n",
      "Epoch : [219] Train loss : [0.025624743529728482] Val Score : [0.9097393418694286])\n",
      "Epoch : [220] Train loss : [0.02493136376142502] Val Score : [0.9097393418694286])\n",
      "Epoch : [221] Train loss : [0.02606943010219506] Val Score : [0.9097393418694286])\n",
      "Epoch : [222] Train loss : [0.02751964862857546] Val Score : [0.9097393418694286])\n",
      "Epoch : [223] Train loss : [0.02474520887647356] Val Score : [0.9097393418694286])\n",
      "Epoch : [224] Train loss : [0.02453247777053288] Val Score : [0.9097393418694286])\n",
      "Epoch : [225] Train loss : [0.024384778791240284] Val Score : [0.9097393418694286])\n",
      "Epoch : [226] Train loss : [0.026990167796611786] Val Score : [0.9097393418694286])\n",
      "Epoch : [227] Train loss : [0.025188861148697988] Val Score : [0.9097393418694286])\n",
      "Epoch   228: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch : [228] Train loss : [0.02547356459711279] Val Score : [0.9097393418694286])\n",
      "Epoch : [229] Train loss : [0.0250684775944267] Val Score : [0.9097393418694286])\n",
      "Epoch : [230] Train loss : [0.026075030277882303] Val Score : [0.9097393418694286])\n",
      "Epoch : [231] Train loss : [0.026050798861043795] Val Score : [0.9097393418694286])\n",
      "Epoch : [232] Train loss : [0.025643431448510716] Val Score : [0.9097393418694286])\n",
      "Epoch : [233] Train loss : [0.025465483644178936] Val Score : [0.9097393418694286])\n",
      "Epoch : [234] Train loss : [0.025954062917402813] Val Score : [0.9097393418694286])\n",
      "Epoch : [235] Train loss : [0.02577678327049528] Val Score : [0.9097393418694286])\n",
      "Epoch : [236] Train loss : [0.025575727224349976] Val Score : [0.9097393418694286])\n",
      "Epoch : [237] Train loss : [0.024761210860950605] Val Score : [0.9097393418694286])\n",
      "Epoch : [238] Train loss : [0.024932343512773514] Val Score : [0.9097393418694286])\n",
      "Epoch   239: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch : [239] Train loss : [0.02548039864216532] Val Score : [0.9097393418694286])\n",
      "Epoch : [240] Train loss : [0.025898910526718413] Val Score : [0.9097393418694286])\n",
      "Epoch : [241] Train loss : [0.02578187600842544] Val Score : [0.9097393418694286])\n",
      "Epoch : [242] Train loss : [0.026161118809665953] Val Score : [0.9097393418694286])\n",
      "Epoch : [243] Train loss : [0.025316748501999036] Val Score : [0.9097393418694286])\n",
      "Epoch : [244] Train loss : [0.027853681040661677] Val Score : [0.9097393418694286])\n",
      "Epoch : [245] Train loss : [0.027525857357042178] Val Score : [0.9097393418694286])\n",
      "Epoch : [246] Train loss : [0.026117988462959017] Val Score : [0.9097393418694286])\n",
      "Epoch : [247] Train loss : [0.02609355002641678] Val Score : [0.9097393418694286])\n",
      "Epoch : [248] Train loss : [0.026023580825754573] Val Score : [0.9097393418694286])\n",
      "Epoch : [249] Train loss : [0.026995671380843436] Val Score : [0.9097393418694286])\n",
      "Epoch   250: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch : [250] Train loss : [0.025383360683918] Val Score : [0.9097393418694286])\n",
      "Epoch : [251] Train loss : [0.025573990706886564] Val Score : [0.9097393418694286])\n",
      "Epoch : [252] Train loss : [0.02506061749798911] Val Score : [0.9097393418694286])\n",
      "Epoch : [253] Train loss : [0.02563177022550787] Val Score : [0.9097393418694286])\n",
      "Epoch : [254] Train loss : [0.025471623986959457] Val Score : [0.9097393418694286])\n",
      "Epoch : [255] Train loss : [0.025437108107975552] Val Score : [0.9097393418694286])\n",
      "Epoch : [256] Train loss : [0.024844332731195858] Val Score : [0.9097393418694286])\n",
      "Epoch : [257] Train loss : [0.026534013184053556] Val Score : [0.9097393418694286])\n",
      "Epoch : [258] Train loss : [0.025141042258058275] Val Score : [0.9097393418694286])\n",
      "Epoch : [259] Train loss : [0.025751021823712757] Val Score : [0.9097393418694286])\n",
      "Epoch : [260] Train loss : [0.025866900171552385] Val Score : [0.9097393418694286])\n",
      "Epoch   261: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch : [261] Train loss : [0.027193000007952963] Val Score : [0.9097393418694286])\n",
      "Epoch : [262] Train loss : [0.02632209924714906] Val Score : [0.9097393418694286])\n",
      "Epoch : [263] Train loss : [0.02534073750887598] Val Score : [0.9097393418694286])\n",
      "Epoch : [264] Train loss : [0.02644356925572668] Val Score : [0.9097393418694286])\n",
      "Epoch : [265] Train loss : [0.026731658993022784] Val Score : [0.9097393418694286])\n",
      "Epoch : [266] Train loss : [0.02664258091577462] Val Score : [0.9097393418694286])\n",
      "Epoch : [267] Train loss : [0.02588756861431258] Val Score : [0.9097393418694286])\n",
      "Epoch : [268] Train loss : [0.02560440344469888] Val Score : [0.9097393418694286])\n",
      "Epoch : [269] Train loss : [0.026955659900392805] Val Score : [0.9097393418694286])\n",
      "Epoch : [270] Train loss : [0.025427221985799924] Val Score : [0.9097393418694286])\n",
      "Epoch : [271] Train loss : [0.026421874229397093] Val Score : [0.9097393418694286])\n",
      "Epoch   272: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch : [272] Train loss : [0.02460927702486515] Val Score : [0.9097393418694286])\n",
      "Epoch : [273] Train loss : [0.0262612413082804] Val Score : [0.9097393418694286])\n",
      "Epoch : [274] Train loss : [0.026698030265314237] Val Score : [0.9097393418694286])\n",
      "Epoch : [275] Train loss : [0.02727082052401134] Val Score : [0.9097393418694286])\n",
      "Epoch : [276] Train loss : [0.025990674272179604] Val Score : [0.9097393418694286])\n",
      "Epoch : [277] Train loss : [0.026376760697790554] Val Score : [0.9097393418694286])\n",
      "Epoch : [278] Train loss : [0.025919519630925997] Val Score : [0.9097393418694286])\n",
      "Epoch : [279] Train loss : [0.024453012804899896] Val Score : [0.9097393418694286])\n",
      "Epoch : [280] Train loss : [0.024145964266998426] Val Score : [0.9097393418694286])\n",
      "Epoch : [281] Train loss : [0.027233682572841644] Val Score : [0.9097393418694286])\n",
      "Epoch : [282] Train loss : [0.025764040648937225] Val Score : [0.9097393418694286])\n",
      "Epoch   283: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch : [283] Train loss : [0.02551070334655898] Val Score : [0.9097393418694286])\n",
      "Epoch : [284] Train loss : [0.026126178247588023] Val Score : [0.9097393418694286])\n",
      "Epoch : [285] Train loss : [0.02593611872621945] Val Score : [0.9097393418694286])\n",
      "Epoch : [286] Train loss : [0.02638429988707815] Val Score : [0.9097393418694286])\n",
      "Epoch : [287] Train loss : [0.027588613065225736] Val Score : [0.9097393418694286])\n",
      "Epoch : [288] Train loss : [0.02679157815873623] Val Score : [0.9097393418694286])\n",
      "Epoch : [289] Train loss : [0.025590990536979268] Val Score : [0.9097393418694286])\n",
      "Epoch : [290] Train loss : [0.025309294728296145] Val Score : [0.9097393418694286])\n",
      "Epoch : [291] Train loss : [0.02489333041012287] Val Score : [0.9097393418694286])\n",
      "Epoch : [292] Train loss : [0.026019016280770302] Val Score : [0.9097393418694286])\n",
      "Epoch : [293] Train loss : [0.025684533640742302] Val Score : [0.9097393418694286])\n",
      "Epoch   294: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch : [294] Train loss : [0.02549043350986072] Val Score : [0.9097393418694286])\n",
      "Epoch : [295] Train loss : [0.025352565305573598] Val Score : [0.9097393418694286])\n",
      "Epoch : [296] Train loss : [0.02540409378707409] Val Score : [0.9097393418694286])\n",
      "Epoch : [297] Train loss : [0.024022412353328297] Val Score : [0.9097393418694286])\n",
      "Epoch : [298] Train loss : [0.025255539853657995] Val Score : [0.9097393418694286])\n",
      "Epoch : [299] Train loss : [0.026958110609224865] Val Score : [0.9097393418694286])\n",
      "Epoch : [300] Train loss : [0.026675669476389885] Val Score : [0.9097393418694286])\n",
      "Epoch : [301] Train loss : [0.026687943509646823] Val Score : [0.9097393418694286])\n",
      "Epoch : [302] Train loss : [0.026114510904465402] Val Score : [0.9097393418694286])\n",
      "Epoch : [303] Train loss : [0.026666407074247087] Val Score : [0.9097393418694286])\n",
      "Epoch : [304] Train loss : [0.02560968803507941] Val Score : [0.9097393418694286])\n",
      "Epoch   305: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch : [305] Train loss : [0.02587839774787426] Val Score : [0.9097393418694286])\n",
      "Epoch : [306] Train loss : [0.02551630139350891] Val Score : [0.9097393418694286])\n",
      "Epoch : [307] Train loss : [0.025438396792326654] Val Score : [0.9097393418694286])\n",
      "Epoch : [308] Train loss : [0.02535916625389031] Val Score : [0.9097393418694286])\n",
      "Epoch : [309] Train loss : [0.026050956387604986] Val Score : [0.9097393418694286])\n",
      "Epoch : [310] Train loss : [0.025501227538500513] Val Score : [0.9097393418694286])\n",
      "Epoch : [311] Train loss : [0.025905262944953784] Val Score : [0.9097393418694286])\n",
      "Epoch : [312] Train loss : [0.025242055633238385] Val Score : [0.9097393418694286])\n",
      "Epoch : [313] Train loss : [0.02690423173563821] Val Score : [0.9097393418694286])\n",
      "Epoch : [314] Train loss : [0.026147394574114254] Val Score : [0.9097393418694286])\n",
      "Epoch : [315] Train loss : [0.0253462873931442] Val Score : [0.9097393418694286])\n",
      "Epoch   316: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch : [316] Train loss : [0.024815476898636137] Val Score : [0.9097393418694286])\n",
      "Epoch : [317] Train loss : [0.024625855098877634] Val Score : [0.9097393418694286])\n",
      "Epoch : [318] Train loss : [0.024982108335409845] Val Score : [0.9097393418694286])\n",
      "Epoch : [319] Train loss : [0.024920404755643437] Val Score : [0.9097393418694286])\n",
      "Epoch : [320] Train loss : [0.025843156235558645] Val Score : [0.9097393418694286])\n",
      "Epoch : [321] Train loss : [0.024881281224744662] Val Score : [0.9097393418694286])\n",
      "Epoch : [322] Train loss : [0.024284453530396734] Val Score : [0.9097393418694286])\n",
      "Epoch : [323] Train loss : [0.025341311203581945] Val Score : [0.9097393418694286])\n",
      "Epoch : [324] Train loss : [0.025600151025823185] Val Score : [0.9097393418694286])\n",
      "Epoch : [325] Train loss : [0.025465997734240124] Val Score : [0.9097393418694286])\n",
      "Epoch : [326] Train loss : [0.025984421904597963] Val Score : [0.9097393418694286])\n",
      "Epoch   327: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch : [327] Train loss : [0.025499989411660602] Val Score : [0.9097393418694286])\n",
      "Epoch : [328] Train loss : [0.024677507313234464] Val Score : [0.9097393418694286])\n",
      "Epoch : [329] Train loss : [0.025019256131989614] Val Score : [0.9097393418694286])\n",
      "Epoch : [330] Train loss : [0.026214307440178736] Val Score : [0.9097393418694286])\n",
      "Epoch : [331] Train loss : [0.025906709155866077] Val Score : [0.9097393418694286])\n",
      "Epoch : [332] Train loss : [0.02632722444832325] Val Score : [0.9097393418694286])\n",
      "Epoch : [333] Train loss : [0.02589320284979684] Val Score : [0.9097393418694286])\n",
      "Epoch : [334] Train loss : [0.0273543048117842] Val Score : [0.9097393418694286])\n",
      "Epoch : [335] Train loss : [0.026906030252575874] Val Score : [0.9097393418694286])\n",
      "Epoch : [336] Train loss : [0.026645034551620483] Val Score : [0.9097393418694286])\n",
      "Epoch : [337] Train loss : [0.02722316315131528] Val Score : [0.9097393418694286])\n",
      "Epoch   338: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch : [338] Train loss : [0.025542054591434344] Val Score : [0.9097393418694286])\n",
      "Epoch : [339] Train loss : [0.024805891726698195] Val Score : [0.9097393418694286])\n",
      "Epoch : [340] Train loss : [0.025753036407487735] Val Score : [0.9097393418694286])\n",
      "Epoch : [341] Train loss : [0.025833288207650185] Val Score : [0.9097393418694286])\n",
      "Epoch : [342] Train loss : [0.02674379838364465] Val Score : [0.9097393418694286])\n",
      "Epoch : [343] Train loss : [0.02540264039167336] Val Score : [0.9097393418694286])\n",
      "Epoch : [344] Train loss : [0.02629080042243004] Val Score : [0.9097393418694286])\n",
      "Epoch : [345] Train loss : [0.02590928546019963] Val Score : [0.9097393418694286])\n",
      "Epoch : [346] Train loss : [0.025549801864794323] Val Score : [0.9097393418694286])\n",
      "Epoch : [347] Train loss : [0.026053023391536305] Val Score : [0.9097393418694286])\n",
      "Epoch : [348] Train loss : [0.026076979402984892] Val Score : [0.9097393418694286])\n",
      "Epoch : [349] Train loss : [0.025812910603625432] Val Score : [0.9097393418694286])\n",
      "Epoch : [350] Train loss : [0.025122379351939474] Val Score : [0.9097393418694286])\n",
      "Epoch : [351] Train loss : [0.025336277538112233] Val Score : [0.9097393418694286])\n",
      "Epoch : [352] Train loss : [0.02633818531674998] Val Score : [0.9097393418694286])\n",
      "Epoch : [353] Train loss : [0.02710930843438421] Val Score : [0.9097393418694286])\n",
      "Epoch : [354] Train loss : [0.027487979935748235] Val Score : [0.9097393418694286])\n",
      "Epoch : [355] Train loss : [0.025198709219694138] Val Score : [0.9097393418694286])\n",
      "Epoch : [356] Train loss : [0.025586267401065146] Val Score : [0.9097393418694286])\n",
      "Epoch : [357] Train loss : [0.02560138888657093] Val Score : [0.9097393418694286])\n",
      "Epoch : [358] Train loss : [0.02544246826853071] Val Score : [0.9097393418694286])\n",
      "Epoch : [359] Train loss : [0.024890147681747164] Val Score : [0.9097393418694286])\n",
      "Epoch : [360] Train loss : [0.025692326948046684] Val Score : [0.9097393418694286])\n",
      "Epoch : [361] Train loss : [0.02515056250350816] Val Score : [0.9097393418694286])\n",
      "Epoch : [362] Train loss : [0.025815892166325023] Val Score : [0.9097393418694286])\n",
      "Epoch : [363] Train loss : [0.02563870219247682] Val Score : [0.9097393418694286])\n",
      "Epoch : [364] Train loss : [0.02571266277560166] Val Score : [0.9097393418694286])\n",
      "Epoch : [365] Train loss : [0.026076716503926685] Val Score : [0.9097393418694286])\n",
      "Epoch : [366] Train loss : [0.024501646203654154] Val Score : [0.9097393418694286])\n",
      "Epoch : [367] Train loss : [0.024389049038290977] Val Score : [0.9097393418694286])\n",
      "Epoch : [368] Train loss : [0.02521783539227077] Val Score : [0.9097393418694286])\n",
      "Epoch : [369] Train loss : [0.027092983147927692] Val Score : [0.9097393418694286])\n",
      "Epoch : [370] Train loss : [0.02470653397696359] Val Score : [0.9097393418694286])\n",
      "Epoch : [371] Train loss : [0.02580260405583041] Val Score : [0.9097393418694286])\n",
      "Epoch : [372] Train loss : [0.025452951501522745] Val Score : [0.9097393418694286])\n",
      "Epoch : [373] Train loss : [0.027043322899511883] Val Score : [0.9097393418694286])\n",
      "Epoch : [374] Train loss : [0.02538924158683845] Val Score : [0.9097393418694286])\n",
      "Epoch : [375] Train loss : [0.026654659105198725] Val Score : [0.9097393418694286])\n",
      "Epoch : [376] Train loss : [0.024699912273458073] Val Score : [0.9097393418694286])\n",
      "Epoch : [377] Train loss : [0.024797706731728146] Val Score : [0.9097393418694286])\n",
      "Epoch : [378] Train loss : [0.02442138083279133] Val Score : [0.9097393418694286])\n",
      "Epoch : [379] Train loss : [0.026344788127711842] Val Score : [0.9097393418694286])\n",
      "Epoch : [380] Train loss : [0.025317136198282242] Val Score : [0.9097393418694286])\n",
      "Epoch : [381] Train loss : [0.024740017152258327] Val Score : [0.9097393418694286])\n",
      "Epoch : [382] Train loss : [0.025807343689458712] Val Score : [0.9097393418694286])\n",
      "Epoch : [383] Train loss : [0.024221216993672506] Val Score : [0.9097393418694286])\n",
      "Epoch : [384] Train loss : [0.026133095313395773] Val Score : [0.9097393418694286])\n",
      "Epoch : [385] Train loss : [0.024687523820570538] Val Score : [0.9097393418694286])\n",
      "Epoch : [386] Train loss : [0.025785347712891444] Val Score : [0.9097393418694286])\n",
      "Epoch : [387] Train loss : [0.027626102524144307] Val Score : [0.9097393418694286])\n",
      "Epoch : [388] Train loss : [0.02614596246608666] Val Score : [0.9097393418694286])\n",
      "Epoch : [389] Train loss : [0.02683254730488573] Val Score : [0.9097393418694286])\n",
      "Epoch : [390] Train loss : [0.024381732834236964] Val Score : [0.9097393418694286])\n",
      "Epoch : [391] Train loss : [0.026497301512530873] Val Score : [0.9097393418694286])\n",
      "Epoch : [392] Train loss : [0.026904266061527387] Val Score : [0.9097393418694286])\n",
      "Epoch : [393] Train loss : [0.024342291855386326] Val Score : [0.9097393418694286])\n",
      "Epoch : [394] Train loss : [0.02712766160922391] Val Score : [0.9097393418694286])\n",
      "Epoch : [395] Train loss : [0.025226935744285583] Val Score : [0.9097393418694286])\n",
      "Epoch : [396] Train loss : [0.025110604773674692] Val Score : [0.9097393418694286])\n",
      "Epoch : [397] Train loss : [0.024619294330477715] Val Score : [0.9097393418694286])\n",
      "Epoch : [398] Train loss : [0.024775985894458636] Val Score : [0.9097393418694286])\n",
      "Epoch : [399] Train loss : [0.024636971897312572] Val Score : [0.9097393418694286])\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder())\n",
    "model.eval()\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53e6313-382b-4f31-a587-1824c579abb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder(\n",
       "    (Encoder): Sequential(\n",
       "      (0): Linear(in_features=30, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (Decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_df, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, thr, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            \n",
    "            _x = model(x)\n",
    "            \n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(model, 0.95, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Class'] = preds\n",
    "submit.to_csv('./submit_autoencoder.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
